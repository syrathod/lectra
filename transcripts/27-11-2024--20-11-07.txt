 as data so that you are able to see it correctly. Yeah, all right. So my data folder is all empty right now. So the audio chunks as the meeting progresses, the audio chunks will be downloaded right here. So keep an eye on this one. Okay, Dilprith, you can start from your end. Explaining stuff. Sir, you need how you need the explanation how we created the streaming platform. Because like our environment was that summary is very common like YouTube videos also you generate summaries, but we wanted to do something different. So like for a small business, like some eduetech company who is trying to create a live streaming platform, they want to give, they are clients, basically the students is summary of the lectures, which is being generated from the ML model. But the query to the mmodel is costly in terms of deploying it to a server it will cause the eduete company. So we need to reduce that mml query cause. So basically that's what we have done. So we have created a streaming platform. What we will do is... Okay, Saij, can you just stop that? This downloading of auditors? Yes, yes, like, now I got it. So we won't be able to show you the transcript and working without any data, right? So... Okay, anyway, fine. Next, please. Well, yeah. Go on, they'll be. So basically, in short, we are reducing the cost of the mml queries. So like, I think, Saij, you can explain what is going on in the mm. Okay, sir. So you can share the system flow as well. All right, all right. So basically, what we wanted to do is rather than working... with pre-recorded videos because that is very too simple to work with. You only have a pre-recorded video. You create transcripts for them and it is a very manual process. We wanted to do automate the entire process. So with that in mind, we have developed the systems such that we are downloading this audio chunks. At the moment, we are working with 60 second chunks. These are downloaded as and when the stream is going on regardless of the platform that is either it's Zoom meetings or Google Meet, it does not matter. It is able to download and basically process, send the chunks in that way regardless of the platform. From the ML point of view, what we are doing is we have created a flow such that it starts by transcribing transcribing is basically that you are converting the speech, the audio data to text data. So we are starting with that. Then we generate the summary for that transcripts. The transcripts will also be stored here once I run this project. So we create a transcript. We summarize on that transcript. And then finally what we are doing is we are since we wanted to automate this entire process. So we are scheduling the summarizer such that it is producing a summary every 10 minutes. So for the chunk or the for the time frame of that 10 minutes, it is generating a summary. So the summary is.